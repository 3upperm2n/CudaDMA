<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Cudadma by lightsighter</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="stylesheets/prism.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <script type="text/javascript">
      function fool_bots(domain, naam, term, label) {
        var result = '';
        result += '<a href="' + 'ma' + 'il' + 'to:' + naam;
        result += '@' + domain + '.' + term;
        result += '">' + label + '<' + '/a>';
        document.write(result);
      }
    </script>
    <div class="wrapper">
      <header>
        <a href="index.html"><h1 class="title"><img width=45px" src="logo.jpg">&nbsp&nbspCudaDMA</h1></a>
        <p>Emulating DMA Engines on GPUs for Performance and Portability</p>

        <!-- <p class="view"><a href="https://github.com/lightsighter/CudaDMA">View the Project on GitHub <small>lightsighter/CudaDMA</small></a></p> -->

        <ul>
          <li><a href="https://github.com/lightsighter/CudaDMA">View On <strong>GitHub</strong></a></li>

          <li><a href="https://github.com/lightsighter/CudaDMA/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/lightsighter/CudaDMA/tarball/master">Download <strong>TAR Ball</strong></a></li>
        </ul>
        <p><a href="sc11.pdf">Supercomputing 2011 Paper</a></p>
        <p><a href="starting.html">Getting Started</a></p>
        <p><a href="model.html">Programming Model</a></p>
        <p><a href="object.html">CudaDMA Object API</a></p>
        <p><a href="two.html">Version 2.0</a></p>
        <p><a href="sequential.html">CudaDMA Sequential</a></p>
        <p><a href="strided.html">CudaDMA Strided</a></p>
        <p><a href="indirect.html">CudaDMA Indirect</a></p>
        <p><a href="practices.html">Best Practices</a></p>
        <p><a href="buffering.html">Buffering Techniques</a></p>
        <p><a href="restrictions.html">Restrictions</a></p>
      </header>
      <footer>
        <p>This project is maintained by <a href="https://github.com/lightsighter">lightsighter</a></p>
        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
      <section>

<h1>
<a id="version-two" class="anchor" href="#version-two" aria-hidden="true"><span class="octicon octicon-link"></span></a>CudaDMAIndirect Version 2.0</h1>

<p>CudaDMAIndirect <a href="two.html">Version 2.0</a> has the same semantics and is characterized by the same parameters as the original <a href="#version-one">CudaDMAIndirect</a>.</p>

<h2>
<a id="constructors-two" class="anchor" href="#constructors-two" aria-hidden="true"><span class="octicon octicon-link"></span></a>Constructors</h2>

<p>From 4-7 template parameters are supported for the new CudaDMAIndirect transfer pattern. All constructors support the new option for specifying the number of <tt>BYTES_PER_THREAD</tt> for outstanding LDG loads. The value of <tt>BYTES_PER_THREAD</tt> must be a multiple of <tt>ALIGNMENT</tt>. By selecting <tt>4*ALIGNMENT</tt> the implementation will default to the Fermi implementation.</p>

<pre><code class="language-cuda">
/* Constructors for use with warp specialization */
CudaDMAIndirect&ltGATHER, true/*specialized*/,ALIGNMENT, 
                BYTES_PER_THREAD, BYTES_PER_ELMT, 
                DMA_THREADS, NUM_ELMTS&gt
  (dmaID, num_compute_threads, dma_threadIdx_start, 
   alternate_stride/*optional*/);

CudaDMAIndirect&ltGATHER, true, ALIGNMENT, 
                BYTES_PER_THREAD, BYTES_PER_ELMT, DMA_THREADS&gt
  (dmaID, num_compute_threads, dma_threadIdx_start, 
   num_elmts, alternate_stride/*optional*/);

CudaDMAIndirect&ltGATHER, true, ALIGNMENT, 
                BYTES_PER_THREAD, BYTES_PER_ELMT&gt
  (dmaID, num_dma_threads, num_compute_threads, dma_threadIdx_start,
   num_elmts, alternate_stride/*optional*/);

CudaDMAIndirect&ltGATHER, true, ALIGNMENT, BYTES_PER_THREAD&gt
  (dmaID, num_dma_threads, num_compute_threads, dma_threadIdx_start,
   bytes_per_elmt, num_elmts, alternate_stride/*optional*/);

/* Constructors for use without warp specialization */
CudaDMAIndirect&ltGATHER, false/*not specialized*/,ALIGNMENT, 
                BYTES_PER_THREAD, BYTES_PER_ELMT, 
                TOTAL_THREADS, NUM_ELMTS&gt
  (alternate_stride/*optional*/, dma_threadIdx_start/*optional*/);

CudaDMAIndirect&ltGATHER, false, ALIGNMENT, BYTES_PER_THREAD, 
                BYTES_PER_ELMT, TOTAL_THREADS&gt
  (num_elmts, alternate_stride/*optional*/, 
   dma_threadIdx_start/*optional*/);

CudaDMAIndirect&ltGATHER, false, ALIGNMENT, 
                BYTES_PER_THREAD, BYTES_PER_ELMT&gt
  (num_elmts, alternate_stride/*optional*/, 
   num_dma_threads/*optional*/, dma_threadIdx_start/*optional*/);

CudaDMAIndirect&ltGATHER, false, ALIGNMENT, BYTES_PER_THREAD&gt
  (bytes_per_elmt, num_elmts, alternate_stride/*optional*/, 
   num_dma_threads/*optional*/, dma_threadIdx_start/*optional*/);
</code></pre>

<p>Unlike previous versions of CudaDMA, the non-warp-specialized implementations also allow you to specify that a subset of the available warps should be used. These are optional parameters. Not specifying them will default to using all the threads in a threadblock for the transfer.</p>

<h2>
<a id="transfer-two" class="anchor" href="#transfer-two" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer Functions</h2>

<p>CudaDMAIndirect supports the following transfer functions.</p>

<pre><code class="language-cuda">
class CudaDMAIndirect {
public:
  // One-Phase Versions
  __device__ void execute_dma(const int *offset_ptr, 
                              const void *src_ptr, void *dst_ptr);

  template&ltbool GLOBAL_LOAD&gt
  __device__ void execute_dma(const int *offset_ptr, const 
                              void *src_ptr, void *dst_ptr);

  template&ltbool GLOBAL_LOAD, CudaDMALoadQualifier LOAD_QUAL, 
           CudaDMAStoreQual STORE_QUAL&gt
  __device__ void execute_dma(const int *offset_ptr, 
                              const void *src_ptr, void *dst_ptr);

  // Two-Phase Versions
  __device__ void start_xfer_async(const int *offset_ptr, 
                                   const void *src_ptr);

  template&ltbool GLOBAL_LOAD&gt
  __device__ void start_xfer_async(const int *offset_ptr, 
                                   const void *src_ptr);

  template&ltbool GLOBAL_LOAD, CudaDMALoadQualifier LOAD_QUAL, 
           CudaDMAStoreQual STORE_QUAL&gt
  __device__ void start_xfer_async(const int *offset_ptr, 
                                   const void *src_ptr);

  __device__ void wait_xfer_finish(void *dst_ptr);

  template&ltbool GLOBAL_LOAD&gt
  __device__ void wait_xfer_finish(void *dst_ptr);

  template&ltbool GLOBAL_LOAD, CudaDMALoadQualifier LOAD_QUAL, 
           CudaDMAStoreQual STORE_QUAL&gt
  __device__ void wait_xfer_finish(void *dst_ptr);
};
</code></pre>

<h2>
<a id="diagnostic-two" class="anchor" href="#diagnostic-two" aria-hidden="true"><span class="octicon octicon-link"></span></a>Diagnostic Functions</h2>

<p>CudaDMAIndirect implements the following host-side diagnostic function. It should be invoked with no template parameters.</p>

<pre><code class="language-cuda">
template&lt...&gt
class CudaDMAIndirect
{
public:
  __host__ static 
  void diagnose(int alignment, int bytes_per_thread, 
                int bytes_per_elmt, int num_dma_threads, 
                bool fully_templated, bool verbose = false);
};

// Example invocation
CudaDMAIndirect&lt&gt::(/*arguments*/);
</code></pre>

<h1>
<a id="version-one" class="anchor" href="#version-one" aria-hidden="true"><span class="octicon octicon-link"></span></a>CudaDMAIndirect Version 1.0</h1>

<h2>
<a id="pattern-one" class="anchor" href="#pattern-one" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pattern Description</h2>

<p>The CudaDMAIndirect transfer pattern performs arbitrary gather and scatter operations for a collection of data blocks in memory. Each block of memory is referred to as an element. The pattern assumes that every element has the same size.</p>

<p>The CudaDMAIndirect pattern can be characterized by four parameters.</p>

<ul>
  <li><tt>GATHER</tt> - a boolean variable indicating whether the transfer is a gather or a scatter operation. true indicates a gather operation while false indicates a scatter.</li>
  <li><tt>ALIGNMENT</tt> - the alignment of all of the elements to be transferred (e.g 4-, 8-, or 16-byte aligned)</li>
  <li><tt>BYTES_PER_ELMT</tt> - the size in bytes of each of the elements</li>
  <li><tt>NUM_ELMTS</tt> - the number of elements to be transferred</li>
</ul>

<p>The call to execute_dma for the indirect pattern takes three arguments instead of the two used by most other CudaDMA patterns.</p>

<pre><code class="language-cuda">
void execute_dma(const int *index_ptr, 
                 const void *src_ptr, void *dst_ptr);
</code></pre>

<p>The index pointer should point to an array of integers that describes the offsets for each of the elements specified as element offsets from source pointer (as opposed to byte offsets). The index pointer array should contain at least <tt>NUM_ELMTS</tt> entries. Additionally, this array must reside in memory visible to all of the DMA threads (either global or shared). It cannot reside in local memory.</p>

<p>In the case of a gather operation, the elements are gathered from the offsets relative to the source pointer of the execute_dma call. The elements are then written into the destination memory in a dense manner in the order of their offsets in the offset array. For example, for each invocation of the execute_dma method the DMA threads will transfer element <tt>i</tt> from the location of <tt>src_ptr+index_ptr[i]*BYTES_PER_ELMT</tt> to the <tt>dst_ptr+i*BYTES_PER_ELMT</tt>.</p>

<p>Conversely, in the case of a scatter operation, elements will be read densely from the source location and then written into the corresponding destination location specified by the offset from the destination pointer for each element.</p>

<h2>
<a id="constructors-one" class="anchor" href="#constructors-one" aria-hidden="true"><span class="octicon octicon-link"></span></a>Constructors</h2>

<p>There are multiple constructors for CudaDMAIndirect that allow the user to specify variable numbers of parameters as compile-time constants via template parameters. Each of the different constructors can be seen below.</p>

<pre><code class="language-cuda">
/* Constructors for use with warp specialization */
cudaDMAIndirect&ltGATHER, true/*specialized*/,ALIGNMENT, 
                BYTES_PER_ELMT, DMA_THREADS, NUM_ELMTS&gt
  (dmaID, num_compute_threads, dma_threadIdx_start);

cudaDMAIndirect&ltGATHER, true, ALIGNMENT, 
                BYTES_PER_ELMT, DMA_THREADS&gt
  (dmaID, num_compute_threads, dma_threadIdx_start, num_elmts);

cudaDMAIndirect&ltGATHER, true, ALIGNMENT, BYTES_PER_ELMT&gt
  (dmaID, num_dma_threads, num_compute_threads, dma_threadIdx_start,
   num_elmts);

cudaDMAIndirect&ltGATHER, true, ALIGNMENT&gt
  (dmaID, num_dma_threads, num_compute_threads, dma_threadIdx_start,
   bytes_per_elmt, num_elmts);

/* Constructors for use without warp specialization */
cudaDMAIndirect&ltGATHER, false/*not specialized*/,ALIGNMENT, 
                BYTES_PER_ELMT, TOTAL_THREADS, NUM_ELMTS&gt
  (void);

cudaDMAIndirect&ltGATHER, false, ALIGNMENT, 
                BYTES_PER_ELMT, TOTAL_THREADS&gt
  (num_elmts);

cudaDMAIndirect&ltGATHER, false, ALIGNMENT, BYTES_PER_ELMT&gt
  (num_elmts);

cudaDMAIndirect&ltGATHER, false, ALIGNMENT&gt
  (bytes_per_elmt, num_elmts);
</code></pre>

<p>All parameters that are not directly related to the CudaDMAIndirect specification are required by the <a href="object.html">CudaDMA API</a>.</p>

<p>The total threads parameter for all the non-warp-specialized constructors indicates how many threads will be used by the CudaDMA object for performing the transfer. When the total number of threads is not passed as a compile-time constant, then the total number of threads is inferred from <tt>blockDim.x</tt> value.</p>

<h2>
<a id="performance-one" class="anchor" href="#performance-one" aria-hidden="true"><span class="octicon octicon-link"></span></a>Performance Considerations</h2>

<p>The best performance for CudaDMAIndirect will be found when supplying as many compile-time constants as possible. Note that knowing the number of DMA threads at compile-time is more important than knowing the number of elements to be transferred at compile-time. Ensuring alignment of data to larger byte boundaries will also lead to higher performance. 16-byte alignment will perform better than 8-byte alignment, and 8-byte alignment will perform better than 4-byte alignment.</p>

<p>In addition, the ordering of offsets may impact performance. The presence of L1 and L2 caches in the Fermi architecture may provide performance gains if elements on the same cache line are loaded by the DMA threads at the same time. Therefore by grouping together offsets that are close in memory higher performance can be achieved.</p>

      </section> 
    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-20524102-4");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
    <script src="javascripts/prism.js"></script> 
  </body>
</html>
