<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Cudadma by lightsighter</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="stylesheets/prism.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <a href="index.html"><h1 class="title"><img width=45px" src="logo.jpg">&nbsp&nbspCudaDMA</h1></a>
        <p>Emulating DMA Engines on GPUs for Performance and Portability</p>

        <!-- <p class="view"><a href="https://github.com/lightsighter/CudaDMA">View the Project on GitHub <small>lightsighter/CudaDMA</small></a></p> -->

        <ul>
          <li><a href="https://github.com/lightsighter/CudaDMA">View On <strong>GitHub</strong></a></li>

          <li><a href="https://github.com/lightsighter/CudaDMA/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/lightsighter/CudaDMA/tarball/master">Download <strong>TAR Ball</strong></a></li>
        </ul>
        <p><a href="sc11.pdf">Supercomputing 2011 Paper</a></p>
        <p><a href="starting.html">Getting Started</a></p>
        <p><a href="model.html">Programming Model</a></p>
        <p><a href="object.html">CudaDMA Object API</a></p>
        <p><a href="two.html">Version 2.0</a></p>
        <p><a href="sequential.html">CudaDMA Sequential</a></p>
        <p><a href="strided.html">CudaDMA Strided</a></p>
        <p><a href="indirect.html">CudaDMA Indirect</a></p>
        <p><a href="practices.html">Best Practices</a></p>
        <p><a href="buffering.html">Buffering Techniques</a></p>
        <p><a href="restrictions.html">Restrictions</a></p>
      </header>
      <footer>
        <p>This project is maintained by <a href="https://github.com/lightsighter">lightsighter</a></p>
        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
      <section>

<h1>
<a id="best-practices" class="anchor" href="#best-practices" aria-hidden="true"><span class="octicon octicon-link"></span></a>Best Practices</h1>

<p>There are several best practices that we use when creating CudaDMA objects. These practices allow CudaDMA objects to achieve high performance. They also can give the user some insight into the performance of the CudaDMA objects that have already been implemented. If you're writing custom CudaDMA objects it's not necessary to abide by all of these recommendations, but they do tend to lead to CudaDMA objects that achieve high performance.</p>

<h2>
<a id="compile-time" class="anchor" href="#compile-time" aria-hidden="true"><span class="octicon octicon-link"></span></a>Compile-Time Constants</h2>

<p>In as many cases as possible, we allow the programmer to specify parameters to the CudaDMA object as compile-time constants via template parameters. The nvcc compiler performs aggressive constant folding at compile-time. Passing parameters as template arguments facilitates this process.</p>

<p>From a programmability standpoint, compile-time constants can make it more difficult to use CudaDMA objects. As a result, we supply default values for template parameters that a programmer would never use and then specialize the templates for these cases to allow arguments to also be passed as runtime arguments to the constructors for CudaDMA objects. By providing multiple versions of a CudaDMA object through template specialization, we give the programmer the option to chose whether to make arguments compile-time or runtime arguments.</p>

<h2>
<a id="loading-maximum" class="anchor" href="#loading-maximum" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading at Maximum Alignment</h2>

<p>The reason that we require the programmer to specify the alignment of the pointers passed to the execute_dma function is that it enables CudaDMA objects to issue loads for more data if the guaranteed alignment is larger. For example, if a 16-byte alignment is guaranteed, then CudaDMA objects will issue 16-byte vector loads (i.e. <tt>float4</tt> or <tt>int4</tt>) whenever possible in order to minimize the number of memory requests that have to be issued for an entire transfer.</p>

<h2>
<a id="outstanding-loads" class="anchor" href="#outstanding-loads" aria-hidden="true"><span class="octicon octicon-link"></span></a>Outstanding Loads Per Thread</h2>

<p>Another performance optimization that we make is to issue as many loads as possible from DMA threads without exceeding the number of load issue slots per thread. By not exceeding the maximum number of outstanding loads per thread we avoid stalling DMA threads while still maximizing MLP. We currently issue four loads per DMA thread per step of a transfer.</p>

<h2>
<a id="prefetching-loads" class="anchor" href="#prefetching-loads" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prefetching Into Registers</h2>

<p>While the CudaDMA API indicates that the DMA threads must first wait for a call to start_async_dma by the compute threads before a transfer can begin, the DMA threads can actually start issuing loads prior to this call as long as they keep their values in registers before issuing their writes. This facilitates even better overlapping of computation and memory accesses.</p>

<p>In some cases users may need strict ordering on memory operations that require that this prefetching is not permitted. In these cases the user can do explicit synchronization using <tt>wait_for_dma_start</tt> and <tt>finish_async_dma</tt> calls around execute_dma_no_sync operations.</p>

<h2>
<a id="hoisting-pointers" class="anchor" href="#hoisting-pointers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hoisting Pointer Arithmetic</h2>

<p>When implementing CudaDMA objects, we also attempt to hoist as much pointer arithmetic into the constructor as possible. By keeping these operations in the constructor we avoid placing them in the inner loop of the DMA threads as part of the execute_dma call. To aid in this process, we often implement CudaDMA objects based on offsets from the <tt>src_ptr</tt> and <tt>dst_ptr</tt> passed to the <tt>execute_dma</tt> call rather than explicit pointers.</p>

<h2>
<a id="memory-conflicts" class="anchor" href="#memory-conflicts" aria-hidden="true"><span class="octicon octicon-link"></span></a>Avoiding Memory Conflicts</h2>

<p>The last optimization that we make when implementing CudaDMA objects is to avoid both bank conflicts in shared memory and replays due to a lack of coalescing in global memory accesses. The CudaDMA API decouples a transfer from its implementation, which enables the implementor of CudaDMA objects to decide which loads are performed by which DMA threads. We implement CudaDMA objects to have maximal coalescing when performing accesses to global memory and minimal bank conflicts when accessing shared memory.</p>

      </section> 
    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-20524102-4");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
    <script src="javascripts/prism.js"></script>
  </body>
</html>
