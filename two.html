<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>CudaDMA</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="stylesheets/prism.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <script type="text/javascript">
      function fool_bots(domain, naam, term, label) {
        var result = '';
        result += '<a href="' + 'ma' + 'il' + 'to:' + naam;
        result += '@' + domain + '.' + term;
        result += '">' + label + '<' + '/a>';
        document.write(result);
      }
    </script>
    <div class="wrapper">
      <header>
        <a href="index.html"><h1 class="title"><img width=45px" src="logo.jpg">&nbsp&nbspCudaDMA</h1></a>
        <p>Emulating DMA Engines on GPUs for Performance and Portability</p>

        <!-- <p class="view"><a href="https://github.com/lightsighter/CudaDMA">View the Project on GitHub <small>lightsighter/CudaDMA</small></a></p> -->

        <ul>
          <li><a href="https://github.com/lightsighter/CudaDMA">View On <strong>GitHub</strong></a></li>

          <li><a href="https://github.com/lightsighter/CudaDMA/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/lightsighter/CudaDMA/tarball/master">Download <strong>TAR Ball</strong></a></li>
        </ul>
        <p><a href="sc11.pdf">Supercomputing 2011 Paper</a></p>
        <p><a href="starting.html">Getting Started</a></p>
        <p><a href="model.html">Programming Model</a></p>
        <p><a href="object.html">CudaDMA Object API</a></p>
        <p><a href="two.html">Version 2.0</a></p>
        <p><a href="sequential.html">CudaDMA Sequential</a></p>
        <p><a href="strided.html">CudaDMA Strided</a></p>
        <p><a href="indirect.html">CudaDMA Indirect</a></p>
        <p><a href="practices.html">Best Practices</a></p>
        <p><a href="buffering.html">Buffering Techniques</a></p>
        <p><a href="restrictions.html">Restrictions</a></p>
      </header>
      <footer>
        <p>This project is maintained by <a href="https://github.com/lightsighter">lightsighter</a></p>
        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
      <section>
<h1>
<a id="version-two" class="anchor" href="#version-two" aria-hidden="true"><span class="octicon octicon-link"></span></a>CudaDMA Version 2.0</h1>

<p>CudaDMA version 2.0 is officially released as of February 3, 2013. Version 2.0 enhances programming with CudaDMA in the following ways:</p>

<ul>
  <li>Modifications to the API to support the Kepler architecture.</li>
  <li>A more flexible API for overlapping transfers with compute.</li>
  <li>Performance debugging feedback on CudaDMA instances.</li>
  <li>Compile-time assertions.</li>
  <li>Better control over caching policies.</li>
</ul>

<p>We describe each of these improvements in detail in the sections below. CudaDMA 2.0 is completely encapsulated by the single header file cudaDMAv2.h found in the <tt>include</tt> directory in the CudaDMA git repository.</p>

<h2>
<a id="release-notes" class="anchor" href="#release-notes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Release Notes</h2>

<ul>
  <li><b>CudaDMA Version 2.0 exercises a correctness bug in nvcc when compiling for arch=compute_20 on 4.0 - 4.2 versions of nvcc only.</b> We've filed a bug with the compiler team and will remove this note when the bug has been fixed. No bugs have been found when targeting arch=compute_30 or arch=compute_35.</li>
  <li>Performance in version 2.0 is highly dependent on the register allocator in ptxas. If it spills CudaDMA's internal buffers to local memory performance is severely degraded. We suggest passing the '-abi=no -v' flags to ptxas and seeing if any local memory is used. If it is, experimentation with the BYTES_PER_THREAD template parameter (described below) may be necessary to get data into registers.</li>
  <li>There is a new example for how to use CudaDMA version 2.0 that illustrates all of the interesting buffering techniques in conjunction with all the new features in version 2.0. The example computes a 2-dimensional stencil over a 3-dimensional space and can be found in 'src/examples/stencil' in the git repository.</li>
</ul>

<h2>
<a id="kepler-support" class="anchor" href="#kepler-support" aria-hidden="true"><span class="octicon octicon-link"></span></a>Support for Kepler</h2>

<p>The release of the new Kepler architecture by NVIDIA exposed several new performance primitives. The one most pertinent to CudaDMA was a new load instruction called LDG loads (see PTX Manual v3.1 Table 90). LDG loads are non-coherent loads performed through the texture cache. Loads issued through the texture cache must return inorder and have longer latency. They also have to benefits. LDG loads have the potential to achieve significantly higher memory bandwidth performance than loads through the L1. More importantly, unlike loads through the L1 where the maximum number of outstanding loads per thread is limited by scoreboarding logic, a single thread can issue a virtually unlimited number of loads without blocking (more on limitations momentarily). This is extremely beneficial for CudaDMA. Rather than requiring 4 or more DMA warps as was necessary on Fermi to saturate memory bandwidth, on Kepler CudaDMA can saturate memory bandwidth with only 1 or 2 DMA warps per threadblock.</p>

<p>Getting the CUDA compiler to automatically generate LDGs is tricky, but CudaDMA makes it easy. To automatically generate LDGs the compiler must prove that you are doing a read-only load from global memory with no aliased pointers in your environment. This requires comprehensive const <tt>__restrict__</tt> annotations and some static analysis which due to its conservative nature usually fails. To use LDGs in CudaDMA, you simply need to pass a single boolean template parameter to execute_dma indicating that you are loading from global memory and CudaDMA will automatically guarantee the generation of LDGs if you're compiling for GPUs with SM generation 3.5 (e.g. K20 and K20c GPUs).</p>

<pre><code class="language-cuda">
// Overloaded execute_dma implementations
class CudaDMA {
public:
  // Old version: still available
  __device__ void execute_dma(const void *src, void *dst);
  // New version: uses LDGs if GLOBAL_LOAD is true 
  // and compiling for compute_35
  template&ltbool GLOBAL_LOAD&gt
  __device__ void execute_dma(const void *src, void *dst);
};
</code></pre>

<p>The number of LDGs outstanding for a thread at a time is actually limited by the number of registers a thread is willing to allocate for the results of outstanding loads. Since register pressure is an application specific property, the new CudaDMA interface includes a new template parameter for all CudaDMA instances: <tt>BYTES_PER_THREAD</tt> which allows the programmer to control the number of registers allocated by CudaDMA for outstanding LDG loads. This must by a multiple of the <tt>ALIGNMENT</tt> template parameter and defaults to <tt>4*ALIGNMENT</tt> which was the baked in value for Fermi (e.g. four outstanding loads at a time, which was the maximum per thread for Fermi's scoreboard logic).</p>

<p>The choice of <tt>BYTES_PER_THREAD</tt> does have an impact on performance. Fewer outstanding loads at a time means less memory-level parallelism is being exploited and performance may suffer. To help make this tradeoff more transparent we introduce performance debugging feedback (see below).</p>

<h2>
<a id="two-phase" class="anchor" href="#two-phase" aria-hidden="true"><span class="octicon octicon-link"></span></a>Two-Phase API</h2>

<p>The introduction of LDG loads also required an extension to the CudaDMA API. Previously, a single call to <tt>execute_dma</tt> was sufficient to perform a transfer efficiently. However the asynchronous nature of LDGs made it desirable to break transfers into two parts: issue a batch of LDGs and then at some later point synchronize waiting for all the LDGs to complete. To facilitate this we required two method calls instead of one. Each CudaDMA instance now supports <tt>start_xfer_async</tt> and <tt>wait_xfer_finish</tt> calls that have identical functionality to a single <tt>execute_dma</tt> call (in fact, <tt>execute_dma</tt> is now implemented by calling these two one immediately after the other). This gives users better control over where transfers are begun and where they are finished. This is most important for non-warp-specialized applications. The execute_dma call is still available on all CudaDMA instances and has identical semantics to previous generations of CudaDMA. Examples of using all the interfaces of CudaDMA are included in the stencil example in the github repository.</p>

<pre><code class="language-cuda">
class CudaDMA {
public:
  // Transfer functions supported by all CudaDMA instances
  __device__ void start_xfer_async(const void *src_ptr);
  template&ltbool GLOBAL_LOAD&gt
  __device__ void start_xfer_async(const void *src_ptr);
public:
  __device__ void wait_xfer_finish(void *dst_ptr);
  template&ltbool GLOBAL_LOAD&gt
  __device__ void wait_xfer_finish(void *dst_ptr);
public:
  __device__ void execute_dma(const void *src_ptr, void *dst_ptr);
  template&ltbool GLOBAL_LOAD&gt
  __device__ void execute_dma(const void *src_ptr, void *dst_ptr);
};
</code></pre>

<h2>
<a id="performance-debugging" class="anchor" href="#performance-debugging" aria-hidden="true"><span class="octicon octicon-link"></span></a>Performance Debugging</h2>

<p>Due to the introduction of the <tt>BYTES_PER_THREAD</tt> parameter programmers have more control over the implementation and performance of CudaDMA instances than they did in previous versions of CudaDMA. To make the performance of CudaDMA instances more transparent, each instance now supports a diagnostic host function that reports on the expected performance of the instance for a given configuration.</p>

<pre><code class="language-cuda">
template<...> class CudaDMASequential {
public:
  __host__
  static void diagnose(int alignment, int bytes_per_thread, 
                       int bytes_per_elmt, int num_dma_threads, 
                       bool fully_templated, bool verbose = false);
};

template<...> class CudaDMAStrided {
public:
  __host__
  static void diagnose(int alignment, int bytes_per_thread, 
                       int bytes_per_elmt, int num_dma_threads, 
                       int num_elmts, bool fully_templated, 
                       bool verbose = false);
};

template<...> class CudaDMAIndirect {
public:
   __host__
   static void diagnose(int alignment, int bytes_per_thread, 
                        int bytes_per_elmt, int num_dma_threads, 
                        int num_elmts, bool fully_templated, 
                        bool verbose = false);
};

// Invocation: note assume default template arguments
CudaDMASequential&lt&gt::diagnose(...);
CudaDMAStrided&lt&gt::diagnose(...);
CudaDMAIndirect&lt&gt::diagnose(...);
</code></pre>

<p>All the arguments that impact performance are passed. The <tt>fully_templated</tt> parameter indicates whether as many arguments as possible are being passed as templates or not. The diagnose functions print to stdout and tell whether the transfers can be completed in a single pass. If the transfers can't be done in a single pass, suggestions are given for improving performance. An example output from a CudaDMAStrided instance is shown below:</p>

<pre><code class="language-cuda">
//********************************************************************
//*                                                                  *
//*              Diagnostic Printing for CudaDMAStrided              *
//*                                                                  *
//********************************************************************

//  PARAMETERS
//    - ALIGNMENT:          4
//    - BYTES-PER-THREAD    4
//    - BYTES-PER-ELMT      420
//    - NUM ELMTS           30
//    - DMA THREADS         416
//    - FULLY TEMPLATED     true

//  Case: Full Elements - element sizes are sufficiently small that 
//                        1 elements can be loading by 4 warps per 
//                        step.  This means there are a total of 3 
//                        elements being loaded per step.
//  TOTAL REQUIRED STEPS: 11
//  DIAGNOSIS: UN-OPTIIZED! This transfer requires multiple steps to 
//                          be performed. See recommendations below...
//  RECOMENDATIONS:
//    - Increase the number of DMA threads particpating in the transfer
//    - Increase the number of bytes available for outstanding loads
//    - Increase element size thereby loading superflous data with the 
//      benefit of improving guaranteed alignment of pointers
</code></pre>

<h2>
<a id="compile-time" class="anchor" href="#compile-time" aria-hidden="true"><span class="octicon octicon-link"></span></a>Compile-Time Assertions</h2>

<p>A short-coming of previous CudaDMA implementations was that they could silently fail if dynamic checks where not intentionally enabled by a user. These dynamic checks relied on runtime assertions which were only supported on later generation GPUs and therefore were rarely checked by much users. The new version of CudaDMA has support for compile time assertions that require no runtime overhead and will always tell you about bugs in your code. Compile-time assertions now check the following properties:</p>

<ul>
  <li><tt>ALIGNMENT</tt> is one of 4-, 8-, or 16-byte aligned.</li>
  <li><tt>BYTES_PER_THREAD</tt> is greater than zero.</li>
  <li><tt>BYTES_PER_THREAD</tt> is a multiple of <tt>ALIGNMENT</tt>.</li>
</ul>

<p>While compile-time assertions don't generate the best error messages, we believe it is preferable to silent failures. If you get a nasty looking static assertion, trace it to its source line in the code and it should be obvious about the invariant you have violated.</p>

<h2>
<a id="controlling-caching" class="anchor" href="#controlling-caching" aria-hidden="true"><span class="octicon octicon-link"></span></a>Controlling Caching</h2>

<p>Finally, CudaDMA exposes a feature of PTX usually only utilized by advanced CUDA programmers: the ability to control the caching effects on load and store operations. While normally caching effects don't impact GPU performance, they can be especially important for kernels that spill registers or rely on re-use of data in the L1 or L2 caches. CudaDMA now explicitly allows users to specify the caching effects to be applied to loads and stores performed by a CudaDMA instance. These effects are well documented in the PTX ISA v3.1 in tables 83 and 84.</p>

<pre><code class="language-cuda">
enum CudaDMALoadQualifier {
  LOAD_CACHE_ALL, // cache at all levels
  LOAD_CACHE_GLOBAL, // cache only in L2
  LOAD_CACHE_STREAMING, // cache at all levels, mark evict first
  LOAD_CACHE_LAST_USE, // invalidate line after use
  LOAD_CACHE_VOLATILE, // don't cache at any level
};

enum CudaDMAStoreQualifier {
  STORE_WRITE_BACK, // write-back all coherent levels
  STORE_CACHE_GLOBAL, // cache in L2 and below
  STORE_CACHE_STREAMING, // mark as evict first
  STORE_CACHE_WRITE_THROUGH, // write through L2 to system memory
};

class CudaDMA {
public:  // Additional versions of CudaDMA transfer functions
  template&ltbool GLOBAL_LOAD, CudaDMALoadQualifier LOAD_QUAL, 
           CudaDMAStoreQualifer STORE_QUAL&gt
  __device__ void start_xfer_async(const void *src_ptr);
  template&ltbool GLOBAL_LOAD, CudaDMALoadQualifier LOAD_QUAL, 
           CudaDMAStoreQualifer STORE_QUAL&gt
  __device__ void wait_xfer_finish(void *dst_ptr);
  template&ltbool GLOBAL_LOAD, CudaDMALoadQualifier LOAD_QUAL, 
           CudaDMAStoreQualifer STORE_QUAL&gt
  __device__ void execute_dma(const void *src_ptr, void *dst_ptr);
};
</code></pre>

      </section> 
    </div>
    <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-20524102-4");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>
    <script src="javascripts/prism.js"></script> 
  </body>
</html>
